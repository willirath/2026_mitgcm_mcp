# Critical Review — Docker-Based Workflow
## MITgcm MCP v2026.02.5

**Scope**: `suggest_experiment_config_tool` quickstart templates +
`validate_incrementally` workflow + `design_experiment` workflow,
evaluated as a complete end-to-end user journey.

---

## What's correct

Before the problems: the templates get several things right.

- `-mpi` flag is present in genmake2 (gotcha-compliant)
- `--allow-run-as-root` is absent (correct per T2.6 gotcha)
- Separate `Dockerfile.amd64` / `Dockerfile.arm64` — right approach
- `MPI_HOME=/usr/lib/x86_64-linux-gnu/mpich` and `aarch64` variant — plausible MPICH paths on Debian
- optfile paths (`linux_amd64_gfortran`, `linux_arm64_gfortran`) match MITgcm conventions
- `ENV NP=1` with `-e NP=...` override is a clean pattern
- `--rm` on docker run prevents container accumulation
- `$(pwd)/output:/experiment/run` volume mount is clean and discoverable
- The four-stage validation approach is genuinely sound

---

## Issues

### 1. NP>1 is not self-contained at runtime (HIGH)

The notes say:

> "Set NP to nPx\*nPy from SIZE.h (ENV NP in Dockerfile or -e NP=... at run time)."

This implies you can change NP by passing `-e NP=4` to `docker run`. You cannot.
`nPx` and `nPy` are compiled into SIZE.h. Changing the MPI decomposition from
1×1 to 2×2 requires editing `code/SIZE.h` and doing a full image rebuild.
`-e NP=...` at runtime only changes what mpirun is told to launch — if the
binary was compiled for NP=1 it will either abort or produce wrong results
with NP>1.

**Fix needed**: note must say explicitly that NP>1 requires a rebuild with
matching SIZE.h `nPx`/`nPy`. The current wording will mislead users.

---

### 2. Stage 2 iteration requires a full Docker rebuild (HIGH)

`validate_incrementally` Stage 2 says:

> "Set nTimeSteps=2 and run."

In the Docker workflow, `input/` is `COPY`d into the image during the
`RUN make` layer. Editing `input/data` to change `nTimeSteps` triggers a
full rebuild — genmake2, make depend, make. For a 10-minute build, running
Stage 2 five times while debugging startup aborts costs an hour.

The obvious fix — mounting `input/` as a read-only volume — is never
mentioned. A user who has only the quickstart has no way to iterate quickly.

```bash
# not suggested but should be:
docker run --rm \
  -v "$(pwd)/input:/experiment/input:ro" \
  -v "$(pwd)/output:/experiment/run" \
  -e NP=1 my_experiment
```

With this, namelist changes don't require a rebuild. The quickstart should
present this as the iteration pattern and reserve rebuilds for code changes.

---

### 3. The `build` key always points to amd64 (MEDIUM)

The top-level `build` instruction:

```
docker build -t my_experiment -f Dockerfile.amd64 .
```

No `--platform` flag, no arch detection, no mention of arm64 here.
The `dockerfile_note` correctly says to pass `--platform linux/arm64` for
Apple Silicon, and the arm64 Dockerfile comment echoes it — but the `build`
key a user is most likely to copy-paste hard-codes amd64 unconditionally.

On an M-series Mac, following the `build` key verbatim either builds a
Rosetta image or silently produces an x86-64 image that runs under emulation.
Neither outcome is flagged.

---

### 4. WORKDIR / CMD mkdir redundancy (LOW)

```dockerfile
WORKDIR /experiment/run
CMD mkdir -p /experiment/run && ...
```

`WORKDIR` already creates the directory at image-build time. The CMD
`mkdir -p` is a no-op in the normal case. When the volume is mounted
(`-v "$(pwd)/output:/experiment/run"`), the host directory replaces it
before CMD runs — `mkdir -p` then runs inside the mounted directory, which
is fine but confusing.

No functional harm, but suggests the CMD was written without thinking through
the interaction with WORKDIR.

---

### 5. Surface forcing is absent from the template entirely (HIGH)

The template carries this note:

> "Surface heat flux applied via data.pkg/OBCS or external forcing file."

The OBCS attribution is wrong (OBCS is the Open Boundary Condition package —
Northern/Southern/Eastern/Western lateral inflow boundaries for regional
models, not surface flux). But the naming error is moot in the Docker context
because there is no pathway to surface forcing at all in the generated
scaffolding:

- `cpp_options`: `["ALLOW_NONHYDROSTATIC", "ALLOW_DIAGNOSTICS"]` — no
  `ALLOW_EXF`, no `ALLOW_OBCS`, no `ALLOW_BULK_FORCE`
- Namelists: `data/PARM01`, `data/PARM03`, `data.eos` only — no `surfQnetFile`
  in PARM05, no `data.exf`, no `data.obcs`

A user building from this template has no compiled mechanism to apply surface
heat flux. The experiment description says *"surface buoyancy flux drives
convection"* — that is the entire physics. Built as-is, the model runs a
rotating box with no thermal forcing. At Stage 3 of `validate_incrementally`,
`theta_mean` would remain static and there would be no convective motion,
leaving the user unable to distinguish a wrong setup from insufficient spinup.

The note is pointing at a door that doesn't exist in the generated scaffolding.

**Fix**: add `ALLOW_EXF` to `cpp_options`, add `data.exf` to the namelist
structure with a surface heat flux field, add `exf` to `packages.conf`, and
add `input/data.exf` to the directory structure. Or, for a simpler approach,
add `surfQnetFile` to `PARM05` with a note that a constant-flux binary field
can be written by `gen_input.py`. Either way, the experiment is currently
missing its driver.

---

### 6. gen_input.py Python environment not addressed (MEDIUM)

The notes say:

> "Generate input fields before docker build: python gen_input.py"

But `gen_input.py` typically imports numpy (and often scipy, xarray, or
netCDF4). The runtime image almost certainly doesn't have these installed
for host use. A user following the quickstart with a bare Python environment
will hit `ModuleNotFoundError: No module named 'numpy'` before they can even
start.

The workflow needs at minimum: "Ensure numpy is available in your local Python
environment (e.g., `pip install numpy`)." Ideally it references a
requirements.txt or conda environment.

---

### 7. STDOUT.0000 location not tied to Docker output (MEDIUM)

`validate_incrementally` Stage 3:

> "Check STDOUT.0000 for: n3dWetPts, theta_mean, dynstat diagnostics"

With the quickstart's `docker run -v "$(pwd)/output:/experiment/run"`,
STDOUT.0000 lands at `output/STDOUT.0000` on the host. The workflow never
says this. A user who looks in `output/` for a file named `STDOUT.0000` will
find it — but only if they know to look there.

The stage 3 description should add: "(find it at `output/STDOUT.0000` with
the quickstart volume mount)."

---

### 8. ln -sf glob is fragile (LOW)

```dockerfile
CMD ... && ln -sf /experiment/input/* . && ...
```

Shell glob expansion in CMD (which runs as `/bin/sh -c`) works, but:

- If `input/` is empty the glob doesn't expand and `ln -sf` receives a
  literal `*` as its argument, failing with "No such file or directory".
- When the run directory is a mounted host volume, symlinks that already
  exist from a previous run with the same output directory are silently
  overwritten by `-f`. This is the intended behaviour but could surprise users.

The empty-directory case is the real trap. It can happen if `gen_input.py`
wasn't run before the build, which is easy to miss.

---

### 9. Stage 4 references "quickstart.run" (LOW)

`validate_incrementally` Stage 4:

> "Mount an output volume (see suggest_experiment_config_tool quickstart.run)"

The key in the actual response is `quickstart` → `run`, not `quickstart.run`.
Dot notation suggests a nested key; the actual structure is a flat dict under
`quickstart`. Minor naming inconsistency but it will confuse users who try to
parse the tool output programmatically.

---

### 10. data.diagnostics missing from namelist structure (carried from D2)

The directory_structure template lists `input/data.diagnostics` with the note:

> "Required when diagnostics package is active. Use
> search_docs_tool('data.diagnostics') for an example."

`data.diagnostics` is absent from `get_namelist_structure_tool()` (D2 in the
structured test report). The pointer works in the wrong direction: users are
told to look up a namelist file that the structure tool doesn't know exists.

---

## Summary table

| # | Severity | Issue |
|---|----------|-------|
| 1 | HIGH | NP>1 requires SIZE.h rebuild — not mentioned; `-e NP=...` alone does not work |
| 2 | HIGH | Stage 2 iteration requires full rebuild; input volume mount never suggested |
| 3 | MEDIUM | `build` key hardcodes amd64; ARM64 instruction buried in separate note |
| 4 | LOW | WORKDIR + CMD mkdir redundancy |
| 5 | HIGH | Surface forcing entirely absent from template (no EXF/PARM05, ALLOW_OBCS not compiled); experiment has no driver |
| 6 | MEDIUM | gen_input.py Python dependencies not addressed |
| 7 | MEDIUM | STDOUT.0000 location not tied to Docker output volume |
| 8 | LOW | `ln -sf input/* .` silently fails if input/ is empty |
| 9 | LOW | Stage 4 note uses "quickstart.run" (dot notation) for a flat key |
| 10 | — | data.diagnostics pointer leads to missing namelist structure entry (D2) |

Issues 1 and 2 are the ones most likely to block a real user on their first
attempt. Issue 5 is a factual error. Issues 3, 6, 7 are documentation gaps
that would cause confusion even for an experienced user following the
template for the first time.
